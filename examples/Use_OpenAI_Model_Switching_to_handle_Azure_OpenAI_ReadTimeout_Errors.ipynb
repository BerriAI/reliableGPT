{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use Model Switching to handle Azure OpenAI ReadTimeout Errors\n",
        "\n",
        "**ðŸš€ Do this in 1 line of code [reliableGPT](https://github.com/BerriAI/reliableGPT)**\n",
        "\n",
        "`reliableGPT(openai.ChatCompletion.create)`\n",
        "\n",
        "Contributions welcome ðŸ˜Š"
      ],
      "metadata": {
        "id": "IGmUM1bskjR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Set-up"
      ],
      "metadata": {
        "id": "adpv0cOhktGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1SBNQcFkTEX"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Set-up your Azure OpenAI Instance\n",
        "import openai\n",
        "import os\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"YOUR_AZURE_OPENAI_ENDPOINT\" #@param {type:\"string\"}\n",
        "os.environ[\"AZURE_OPENAI_KEY\"] = \"YOUR_AZURE_OPENAI_KEY\" #@param {type:\"string\"}\n",
        "os.environ[\"AZURE_DEPLOYMENT_ID\"] = \"YOUR_AZURE_DEPLOYMENT_ID\" #@param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_BACKUP_OPENAI_KEY\" #@param {type:\"string\"}\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "openai.api_version = \"2023-05-15\"\n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")"
      ],
      "metadata": {
        "id": "G2UPpnpntrqN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Model Switching\n",
        "\n",
        "Here's how we'll do this:\n",
        "- `Wrapper Function`: We'll wrap the OpenAI endpoint, to catch any errors that might occur\n",
        "- `Fallback Strategy`: If an error occurs, we'll rotate through different models\n",
        "- `Backup OpenAI Key`: Our fallback will be to call the raw OpenAI endpoints instead"
      ],
      "metadata": {
        "id": "EKG2m0t9t57w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "import copy\n",
        "import random\n",
        "import signal\n",
        "\n",
        "# Our fallback strategy\n",
        "def fallback_fn(fn, args, kwargs, fallback_strategy):\n",
        "  try:\n",
        "    # preserve the azure endpoint details\n",
        "    azure_endpoint_details = openai.__dict__.copy()\n",
        "    # get the backup openai key\n",
        "    backup_openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    # switch to the raw openai model instead of using azure.\n",
        "    openai.api_type = \"openai\"\n",
        "    openai.api_base = \"https://api.openai.com/v1\"\n",
        "    openai.api_version = None\n",
        "    openai.api_key = backup_openai_key\n",
        "    new_kwargs_except_engine = {\n",
        "      k: v\n",
        "      for k, v in kwargs.items()\n",
        "      if k != \"engine\" and k!= \"deployment_id\"\n",
        "    }\n",
        "    print(f\"new kwargs: {new_kwargs_except_engine}\")\n",
        "    for model in fallback_strategy:\n",
        "      new_kwargs_except_engine['model'] = model\n",
        "      completion = fn(**new_kwargs_except_engine)\n",
        "      if completion != None:\n",
        "        break\n",
        "    # reset openai back to azure,\n",
        "    openai.api_type = azure_endpoint_details[\"api_type\"]\n",
        "    openai.api_base = azure_endpoint_details[\"api_base\"]\n",
        "    openai.api_version = azure_endpoint_details[\"api_version\"]\n",
        "    openai.api_key = azure_endpoint_details[\"api_key\"]\n",
        "    return completion\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return None\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutError(\"Function execution timed out\")\n",
        "\n",
        "# Our Wrapper Function!!\n",
        "def wrapper_fn(fn, fallback_strategy=[\"gpt-4\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo\"]): # setting our default fallback strategy, in case OpenAI fails\n",
        "  def wrapped_fn(*args, **kwargs):\n",
        "    # Set the timeout signal handler <- to break out of requests in case they take too long to execute\n",
        "    signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "    # Set the timeout alarm for 10s\n",
        "    signal.alarm(10)\n",
        "    try:\n",
        "      print(\"received request!\")\n",
        "      result = fn(*args, **kwargs)\n",
        "    except Exception as e:\n",
        "      traceback.print_exc()\n",
        "      # Disable the timeout alarm\n",
        "      signal.alarm(0)\n",
        "      print(f\"args: {args}\")\n",
        "      print(f\"kwargs: {kwargs}\")\n",
        "      result = fallback_fn(fn, args, kwargs, fallback_strategy=fallback_strategy)\n",
        "      if result == None:\n",
        "        raise e\n",
        "    return result\n",
        "  return wrapped_fn"
      ],
      "metadata": {
        "id": "EjMtOUaxt4F7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping our OpenAI call!"
      ],
      "metadata": {
        "id": "ACBYPjhW0gln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_fn = openai.ChatCompletion.create # save the original reference (good practice)\n",
        "openai.ChatCompletion.create = wrapper_fn(openai.ChatCompletion.create)"
      ],
      "metadata": {
        "id": "iIabJS530jls"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ Test with 100 OpenAI Calls"
      ],
      "metadata": {
        "id": "TtMoyw5V0sXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "  # create a chat completion\n",
        "  chat_completion = openai.ChatCompletion.create(deployment_id=os.getenv(\"AZURE_DEPLOYMENT_ID\"), model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
        "  # print the completion\n",
        "  print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "BKXk-GuG0y5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}